# üéì **PROYECTO FINAL DE INTELIGENCIA ARTIFICIAL**

## **Clasificaci√≥n Autom√°tica de Correos Electr√≥nicos: Detecci√≥n de Spam mediante Algoritmo Naive Bayes**

---

### **Informaci√≥n del Proyecto**

- **T√≠tulo:** Sistema de Clasificaci√≥n de Correos Electr√≥nicos usando Naive Bayes
- **Tipo de Aprendizaje:** Aprendizaje Supervisado
- **Algoritmo:** Clasificador Bayesiano Ingenuo (Naive Bayes)
- **Tarea:** Clasificaci√≥n Binaria (Spam/Ham)
- **Lenguaje de Programaci√≥n:** Python 3.7+
- **Fecha:** 2026

---

### **Resumen Ejecutivo**

Este proyecto implementa un sistema completo de detecci√≥n de spam en correos electr√≥nicos utilizando el algoritmo Naive Bayes desde cero. El sistema incluye:

- **Preprocesamiento de texto** completo (normalizaci√≥n, tokenizaci√≥n, eliminaci√≥n de stopwords)
- **Implementaci√≥n del modelo Naive Bayes** con suavizado de Laplace
- **Evaluaci√≥n exhaustiva** con m√∫ltiples m√©tricas (Accuracy, Precision, Recall, F1-Score)
- **Visualizaciones profesionales** de resultados y an√°lisis
- **An√°lisis estad√≠stico detallado** con interpretaci√≥n de resultados
- **Reportes exportables** en formato JSON
- **Persistencia del modelo** (guardar/cargar `.pkl`) y script de uso `usar_modelo.py`
- **Datasets peque√±o y grande** (`datos.csv`, `datos_grande.csv`) con generador autom√°tico

El modelo logra un desempe√±o competitivo en la tarea de clasificaci√≥n binaria, demostrando la efectividad del algoritmo Naive Bayes para problemas de procesamiento de lenguaje natural.

---

## **1. Descripci√≥n del Problema**

Este proyecto aborda la tarea de **clasificar autom√°ticamente correos electr√≥nicos** para determinar si un mensaje es *spam* (correo no deseado) o *ham* (correo leg√≠timo).  
El objetivo es entrenar un modelo desde cero que aprenda a identificar patrones en el texto para realizar predicciones correctas.

Este problema es adecuado para un proyecto de IA porque:

- Es f√°cil de comprender y replicar.  
- Puede resolverse sin modelos preentrenados.  
- Permite aplicar t√©cnicas b√°sicas de procesamiento de texto y aprendizaje autom√°tico.  
- Dispone de datos simples y etiquetados.

---

## **2. Tipo de Aprendizaje Utilizado: Aprendizaje Supervisado**

El aprendizaje supervisado consiste en entrenar un modelo a partir de:

- **Datos de entrada**: los mensajes de correo.  
- **Etiquetas conocidas**: spam / ham.

El objetivo del modelo es aprender una funci√≥n:

\[
f(x) \rightarrow y
\]

donde:  
- \(x\) representa las caracter√≠sticas extra√≠das del mensaje,  
- \(y\) es la etiqueta asignada al mensaje.

La tarea es una **clasificaci√≥n binaria**, lo que la hace ideal para introducir los fundamentos del aprendizaje supervisado.

---

## **3. Conjunto de Datos**

### **Descripci√≥n del Dataset**

Para este estudio se emplean **dos datasets balanceados** de mensajes en espa√±ol, etiquetados como spam o ham:

**Datasets incluidos:**
- **`datos.csv` (peque√±o):** 180 mensajes (90 spam, 90 ham)
- **`datos_grande.csv` (grande):** 1500 mensajes (750 spam, 750 ham)

**Caracter√≠sticas generales:**
- **Formato:** Archivos CSV con columnas: `id`, `mensaje`, `etiqueta`
- **Idioma:** Espa√±ol
- **Balance:** Datasets balanceados para evitar sesgos en el entrenamiento
- **Origen:** `datos_grande.csv` se genera autom√°ticamente a partir de plantillas

**Nota:** El script `main.py` intenta usar primero `datos_grande.csv`. Si no existe, usa `datos.csv`.  
Para regenerar el dataset grande, ejecuta `python generar_dataset_grande.py`.

**Ejemplos de datos:**

| id | mensaje                                        | etiqueta |
|----|------------------------------------------------|----------|
| 1  | "Gana dinero r√°pido haciendo clic aqu√≠"        | spam     |
| 2  | "Reuni√≥n confirmada para ma√±ana"               | ham      |
| 3  | "Oferta limitada, compra ahora"                | spam     |
| 4  | "Adjunto env√≠o los documentos solicitados"     | ham      |

Los datasets est√°n dise√±ados para demostrar el funcionamiento del modelo de forma clara y pueden ampliarse para obtener mejores resultados en producci√≥n.

---

## **4. Preprocesamiento de Datos**

El texto se procesa mediante los siguientes pasos:

1. Conversi√≥n a min√∫sculas.  
2. Eliminaci√≥n de signos de puntuaci√≥n.  
3. Tokenizaci√≥n.  
4. Eliminaci√≥n de palabras irrelevantes (stopwords).  
5. Conversi√≥n del texto a representaci√≥n num√©rica mediante **Bolsa de Palabras (Bag of Words)**.

El resultado es que cada mensaje se vuelve un vector que indica la frecuencia de palabras relevantes.

---

## **5. Modelo Seleccionado: Naive Bayes**

### **¬øPor qu√© Naive Bayes?**

- Es simple de implementar desde cero.  
- Funciona especialmente bien con texto.  
- Tiene bajo costo computacional.  
- Se basa en fundamentos estad√≠sticos claros.

### **Idea del Modelo**

El modelo calcula:

\[
P(\text{spam} \mid \text{mensaje})
\quad \text{y} \quad
P(\text{ham} \mid \text{mensaje})
\]

Asignando al mensaje la clase con mayor probabilidad.

Para evitar que palabras nuevas produzcan errores, se utiliza **suavizado de Laplace**:

\[
P(\text{palabra}|\text{clase}) = \frac{\text{frecuencia} + 1}{\text{total palabras} + V}
\]

donde \(V\) es el tama√±o del vocabulario.

---

## **6. Entrenamiento del Modelo**

Durante el entrenamiento se calculan:

- La probabilidad de que un mensaje sea spam o ham.  
- La frecuencia de cada palabra en ambos tipos de mensajes.  
- Las probabilidades condicionales de cada palabra seg√∫n la clase.  

As√≠ el modelo aprende qu√© t√©rminos son m√°s comunes en correos no deseados y cu√°les aparecen en mensajes leg√≠timos.

---

## **7. Evaluaci√≥n del Modelo**

Se utilizan las m√©tricas cl√°sicas:

- **Accuracy (Exactitud)**  
- **Precision (Precisi√≥n)**  
- **Recall (Sensibilidad)**  
- **F1-score**

Un ejemplo esperado con el dataset peque√±o (`datos.csv`):

| M√©trica   | Valor |
|-----------|-------|
| Accuracy  | 0.92  |
| Precisi√≥n | 0.90  |
| Recall    | 0.93  |
| F1-score  | 0.91  |

---

## **8. Resultados y An√°lisis**

El modelo logra distinguir t√©rminos clave que indican spam, como:

- ‚Äúdinero‚Äù,  
- ‚Äúr√°pido‚Äù,  
- ‚Äúclic‚Äù,  
- ‚Äúcompra‚Äù,  
- ‚Äúoferta‚Äù.

Mientras que los correos ham presentan vocabulario m√°s formal y administrativo.

El desempe√±o del algoritmo muestra que **Naive Bayes es adecuado para tareas de clasificaci√≥n de texto simples**.

---

## **9. Limitaciones**

- No capta el orden de las palabras.  
- Supone independencia entre t√©rminos, lo cual no siempre es cierto.  
- Puede fallar en textos ir√≥nicos o muy ambiguos.  
- Requiere un buen preprocesamiento para lograr buenos resultados.

---

## **10. Conclusiones**

- El problema de clasificaci√≥n de correos es ideal para aprendizaje supervisado.  
- Naive Bayes permite implementar un modelo desde cero, sencillo y eficiente.  
- A pesar de su simplicidad, ofrece buena precisi√≥n en tareas de filtrado de spam.  
- Con mayor cantidad de datos, el modelo podr√≠a mejorar a√∫n m√°s su rendimiento.

---

## **11. Arquitectura del C√≥digo**

### **Estructura del Proyecto**

El proyecto est√° organizado en m√≥dulos separados para facilitar la comprensi√≥n y el mantenimiento:

```
spam-detector-ai/
‚îú‚îÄ‚îÄ README.md                      # Documentaci√≥n completa
‚îú‚îÄ‚îÄ INSTALACION.md                 # Gu√≠a de instalaci√≥n
‚îú‚îÄ‚îÄ GUIA_MODELO_PERSISTENTE.md     # Gu√≠a de persistencia del modelo
‚îú‚îÄ‚îÄ EXPOSICION_Modelo_Spam_NaiveBayes.md
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias del proyecto
‚îú‚îÄ‚îÄ instalar_dependencias.sh       # Script de instalaci√≥n (macOS/Linux)
‚îú‚îÄ‚îÄ datos.csv                      # Dataset peque√±o (180 mensajes)
‚îú‚îÄ‚îÄ datos_grande.csv               # Dataset grande (1500 mensajes)
‚îú‚îÄ‚îÄ generar_dataset_grande.py      # Generador del dataset grande
‚îú‚îÄ‚îÄ preprocesamiento.py            # Funciones de preprocesamiento de texto
‚îú‚îÄ‚îÄ modelo.py                      # Implementaci√≥n de Naive Bayes desde cero
‚îú‚îÄ‚îÄ evaluacion.py                  # M√©tricas de evaluaci√≥n
‚îú‚îÄ‚îÄ analisis.py                    # An√°lisis estad√≠stico y reporte JSON
‚îú‚îÄ‚îÄ visualizaciones.py             # Generaci√≥n de gr√°ficos profesionales
‚îú‚îÄ‚îÄ usar_modelo.py                 # Carga y uso del modelo guardado
‚îú‚îÄ‚îÄ main.py                        # Script principal que ejecuta el pipeline completo
‚îú‚îÄ‚îÄ modelos/                       # Modelos guardados (se genera)
‚îî‚îÄ‚îÄ resultados/                    # Resultados y gr√°ficos (se genera)
```

### **Flujo de Datos**

El pipeline completo funciona de la siguiente manera:

```
datos_grande.csv (si existe) / datos.csv
    ‚Üì
[Carga de Datos] ‚Üí mensajes, etiquetas
    ‚Üì
[Divisi√≥n Train/Test] ‚Üí X_train, X_test, y_train, y_test
    ‚Üì
[Preprocesamiento] ‚Üí tokens normalizados, vocabulario
    ‚Üì
[Entrenamiento del Modelo] ‚Üí modelo entrenado con probabilidades
    ‚Üì
[Evaluaci√≥n] ‚Üí m√©tricas (accuracy, precision, recall, F1)
    ‚Üì
[An√°lisis + Visualizaciones + Reporte JSON]
    ‚Üì
[Guardado del Modelo] ‚Üí modelos/modelo_entrenado.pkl
```

### **Descripci√≥n de M√≥dulos**

#### **preprocesamiento.py**
Contiene todas las funciones para preparar el texto antes de ser procesado por el modelo:
- `normalizar_texto()`: Convierte a min√∫sculas y elimina puntuaci√≥n
- `tokenizar()`: Divide el texto en palabras individuales
- `eliminar_stopwords()`: Remueve palabras comunes sin significado √∫til
- `crear_bag_of_words()`: Convierte textos a vectores num√©ricos
- `preprocesar_mensaje()`: Pipeline completo para un mensaje
- `preprocesar_dataset()`: Pipeline completo para un conjunto de datos

#### **modelo.py**
Implementa el clasificador Naive Bayes:
- `NaiveBayesSpamDetector`: Clase principal del modelo
  - `entrenar()`: Aprende probabilidades desde los datos
  - `predecir()`: Clasifica un mensaje como spam o ham
  - `predecir_proba()`: Retorna probabilidades para ambas clases
  - `obtener_palabras_importantes()`: Identifica palabras clave
  - `guardar()` / `cargar()`: Persistencia del modelo en `.pkl`
  - `continuar_entrenamiento()`: Reentrenamiento incremental

#### **evaluacion.py**
Calcula m√©tricas de desempe√±o:
- `matriz_confusion()`: Matriz de confusi√≥n (TP, TN, FP, FN)
- `calcular_accuracy()`: Exactitud general
- `calcular_precision()`: Precisi√≥n (spam como clase positiva)
- `calcular_recall()`: Sensibilidad
- `calcular_f1_score()`: F1-score (balance entre precisi√≥n y recall)
- `evaluar_modelo()`: Funci√≥n que calcula todas las m√©tricas

#### **analisis.py**
An√°lisis estad√≠stico del dataset y reporte:
- `analizar_distribucion_datos()`: Estad√≠sticas y balance
- `analizar_errores()`: Falsos positivos/negativos
- `generar_reporte_completo()`: Reporte JSON consolidado
- `imprimir_analisis_completo()`: Resumen legible en consola

#### **visualizaciones.py**
Genera gr√°ficos en `resultados/`:
- M√©tricas, matriz de confusi√≥n, distribuci√≥n de clases
- Palabras importantes y gr√°fico radar comparativo

#### **generar_dataset_grande.py**
Genera `datos_grande.csv` con m√°s ejemplos balanceados.

#### **usar_modelo.py**
Carga `modelos/modelo_entrenado.pkl` y clasifica mensajes sin reentrenar.

#### **main.py**
Orquesta todo el pipeline:
1. Carga datos desde CSV
2. Divide en entrenamiento y prueba
3. Preprocesa los mensajes
4. Entrena el modelo
5. Eval√∫a con m√©tricas
6. Muestra ejemplos de predicci√≥n
7. Analiza palabras importantes
8. Realiza an√°lisis estad√≠stico
9. Genera visualizaciones (si est√°n disponibles)
10. Exporta reporte JSON y guarda el modelo

---

## **12. Explicaci√≥n Detallada del Modelo Naive Bayes**

### **Fundamentos Matem√°ticos**

El algoritmo Naive Bayes est√° basado en el **Teorema de Bayes**:

\[
P(\text{clase} \mid \text{mensaje}) = \frac{P(\text{mensaje} \mid \text{clase}) \cdot P(\text{clase})}{P(\text{mensaje})}
\]

Para clasificaci√≥n, solo necesitamos comparar probabilidades, por lo que podemos ignorar el denominador:

\[
P(\text{spam} \mid \text{mensaje}) \propto P(\text{mensaje} \mid \text{spam}) \cdot P(\text{spam})
\]

\[
P(\text{ham} \mid \text{mensaje}) \propto P(\text{mensaje} \mid \text{ham}) \cdot P(\text{ham})
\]

### **Suposici√≥n de Independencia (Naive)**

El modelo asume que las palabras son independientes entre s√≠ (aunque esto no es completamente cierto en la realidad, funciona bien en la pr√°ctica). Esto nos permite calcular:

\[
P(\text{mensaje} \mid \text{clase}) = P(palabra_1 \mid \text{clase}) \cdot P(palabra_2 \mid \text{clase}) \cdot ... \cdot P(palabra_n \mid \text{clase})
\]

\[
P(\text{mensaje} \mid \text{clase}) = \prod_{i=1}^{n} P(palabra_i \mid \text{clase})
\]

### **C√°lculo de Probabilidades**

#### **Probabilidades a Priori**

Se calculan simplemente como la proporci√≥n de mensajes de cada clase:

\[
P(\text{spam}) = \frac{\text{n√∫mero de mensajes spam}}{\text{n√∫mero total de mensajes}}
\]

\[
P(\text{ham}) = \frac{\text{n√∫mero de mensajes ham}}{\text{n√∫mero total de mensajes}}
\]

#### **Probabilidades Condicionales**

La probabilidad de una palabra dado una clase se calcula como:

\[
P(palabra \mid \text{clase}) = \frac{\text{frecuencia de palabra en clase}}{\text{total de palabras en clase}}
\]

#### **Suavizado de Laplace**

Para evitar problemas cuando una palabra no aparece en el entrenamiento de una clase (probabilidad = 0), usamos suavizado:

\[
P(palabra \mid \text{clase}) = \frac{\text{frecuencia} + \alpha}{\text{total palabras} + \alpha \cdot V}
\]

donde:
- \(\alpha = 1.0\) (par√°metro de suavizado, com√∫nmente 1)
- \(V\) = tama√±o del vocabulario (palabras √∫nicas)

### **Uso de Logaritmos para Estabilidad Num√©rica**

Al multiplicar muchas probabilidades peque√±as, podemos tener problemas de **underflow** (n√∫meros demasiado peque√±os para representar). Por eso usamos logaritmos:

\[
\log(P(\text{clase} \mid \text{mensaje})) = \log(P(\text{clase})) + \sum_{i=1}^{n} \log(P(palabra_i \mid \text{clase}))
\]

Esto convierte multiplicaciones en sumas, que son m√°s estables num√©ricamente.

### **Ejemplo Num√©rico Paso a Paso**

Supongamos que tenemos:

**Mensaje**: "dinero r√°pido"

**Datos de entrenamiento**:
- Spam: "dinero f√°cil dinero" (dinero aparece 2 veces, f√°cil 1 vez)
- Ham: "reuni√≥n ma√±ana" (reuni√≥n y ma√±ana aparecen 1 vez cada una)

**Vocabulario**: {dinero, f√°cil, reuni√≥n, ma√±ana} ‚Üí V = 4

**Paso 1: Probabilidades a priori**
- Total mensajes: 2
- P(spam) = 1/2 = 0.5
- P(ham) = 1/2 = 0.5

**Paso 2: Probabilidades condicionales con suavizado (Œ±=1)**

Para spam:
- Total palabras en spam: 3
- P(dinero|spam) = (2 + 1) / (3 + 1√ó4) = 3/7 ‚âà 0.429
- P(r√°pido|spam) = (0 + 1) / (3 + 1√ó4) = 1/7 ‚âà 0.143

Para ham:
- Total palabras en ham: 2
- P(dinero|ham) = (0 + 1) / (2 + 1√ó4) = 1/6 ‚âà 0.167
- P(r√°pido|ham) = (0 + 1) / (2 + 1√ó4) = 1/6 ‚âà 0.167

**Paso 3: Calcular probabilidades finales**

Para spam:
- log(P(spam|mensaje)) = log(0.5) + log(0.429) + log(0.143) ‚âà -0.693 - 0.846 - 1.946 ‚âà -3.485
- P(spam|mensaje) ‚âà exp(-3.485) ‚âà 0.031

Para ham:
- log(P(ham|mensaje)) = log(0.5) + log(0.167) + log(0.167) ‚âà -0.693 - 1.792 - 1.792 ‚âà -4.277
- P(ham|mensaje) ‚âà exp(-4.277) ‚âà 0.014

**Paso 4: Normalizar y decidir**

- P(spam|mensaje) normalizada ‚âà 0.031 / (0.031 + 0.014) ‚âà 0.689
- P(ham|mensaje) normalizada ‚âà 0.014 / (0.031 + 0.014) ‚âà 0.311

**Resultado**: El mensaje se clasifica como **spam** (mayor probabilidad).

---

## **13. Gu√≠a Paso a Paso del C√≥digo**

### **Flujo de Ejecuci√≥n del Script Principal (main.py)**

#### **Paso 1: Carga de Datos**

```python
import os
archivo = 'datos_grande.csv' if os.path.exists('datos_grande.csv') else 'datos.csv'
mensajes, etiquetas = cargar_datos(archivo)
```

**Qu√© hace:**
- Lee el archivo CSV l√≠nea por l√≠nea
- Extrae los campos `mensaje` y `etiqueta`
- Valida que las etiquetas sean 'spam' o 'ham'
- Retorna dos listas: una con mensajes y otra con etiquetas
 - Usa `datos_grande.csv` si existe, si no usa `datos.csv`

**Ejemplo de datos cargados:**
- mensajes = ["Gana dinero r√°pido", "Reuni√≥n confirmada", ...]
- etiquetas = ["spam", "ham", ...]

#### **Paso 2: Divisi√≥n de Datos**

```python
mensajes_train, mensajes_test, etiquetas_train, etiquetas_test = dividir_datos(...)
```

**Qu√© hace:**
- Mezcla los datos aleatoriamente
- Separa el 80% para entrenamiento y 20% para prueba
- Esto permite evaluar el modelo con datos que no ha visto durante el entrenamiento

**¬øPor qu√© es importante?**
- Eval√∫a si el modelo generaliza bien a datos nuevos
- Previene el sobreajuste (overfitting)

#### **Paso 3: Preprocesamiento**

```python
mensajes_train_preproc, vocab_train, _ = preprocesar_dataset(mensajes_train)
```

**Proceso interno:**

1. **Normalizaci√≥n** (`normalizar_texto`):
   - "¬°Gana DINERO!" ‚Üí "gana dinero"
   - Elimina puntuaci√≥n y convierte a min√∫sculas

2. **Tokenizaci√≥n** (`tokenizar`):
   - "gana dinero" ‚Üí ["gana", "dinero"]
   - Divide el texto en palabras

3. **Eliminaci√≥n de stopwords** (`eliminar_stopwords`):
   - ["el", "dinero", "es", "f√°cil"] ‚Üí ["dinero", "f√°cil"]
   - Remueve palabras comunes sin significado

4. **Creaci√≥n de vocabulario**:
   - Recopila todas las palabras √∫nicas de todos los mensajes
   - Asigna un √≠ndice √∫nico a cada palabra

**Resultado:** Lista de mensajes donde cada uno es una lista de tokens relevantes.

#### **Paso 4: Entrenamiento del Modelo**

```python
modelo = NaiveBayesSpamDetector(alpha=1.0)
modelo.entrenar(mensajes_train_preproc, etiquetas_train)
```

**Proceso interno de `entrenar()`:**

1. **Calcula probabilidades a priori:**
   ```python
   spam_count = contar mensajes con etiqueta 'spam'
   self.prob_spam = spam_count / total_mensajes
   ```

2. **Cuenta frecuencias de palabras:**
   ```python
   Para cada mensaje:
       Si es spam:
           Incrementar contador de palabras en spam_words
       Si es ham:
           Incrementar contador de palabras en ham_words
   ```

3. **Calcula probabilidades condicionales:**
   ```python
   Para cada palabra en vocabulario:
       P(palabra|spam) = (frecuencia_spam + alpha) / (total_spam + alpha * V)
       P(palabra|ham) = (frecuencia_ham + alpha) / (total_ham + alpha * V)
       Guardar log(P(palabra|clase)) para evitar underflow
   ```

**Resultado:** Modelo con todas las probabilidades aprendidas.

#### **Paso 5: Predicci√≥n**

```python
prediccion = modelo.predecir(mensaje_preproc)
```

**Proceso interno:**

1. **Preprocesa el mensaje** (si es necesario)

2. **Calcula log-probabilidades:**
   ```python
   log_P_spam = log(P(spam)) + sum(log(P(palabra|spam)) para cada palabra)
   log_P_ham = log(P(ham)) + sum(log(P(palabra|ham)) para cada palabra)
   ```

3. **Normaliza probabilidades:**
   ```python
   P_spam = exp(log_P_spam - max(log_P_spam, log_P_ham))
   P_ham = exp(log_P_ham - max(log_P_spam, log_P_ham))
   Normalizar para que sumen 1.0
   ```

4. **Retorna la clase con mayor probabilidad**

#### **Paso 6: Evaluaci√≥n**

```python
resultados = evaluar_modelo(modelo, X_test, y_test)
```

**Proceso:**

1. **Hace predicciones** para todos los mensajes de prueba
2. **Calcula matriz de confusi√≥n:**
   - TP: Spam correctamente identificado
   - TN: Ham correctamente identificado
   - FP: Ham marcado como spam (error)
   - FN: Spam marcado como ham (error)

3. **Calcula m√©tricas:**
   - Accuracy = (TP + TN) / Total
   - Precision = TP / (TP + FP)
   - Recall = TP / (TP + FN)
   - F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)

#### **Paso 7: An√°lisis y palabras importantes**

Se identifican palabras m√°s caracter√≠sticas por clase y se generan estad√≠sticas del dataset:
- Distribuci√≥n y balance de clases
- Longitud promedio de mensajes
- Errores m√°s comunes (FP/FN)

#### **Paso 8: Visualizaciones (opcional)**

Si est√°n instaladas las dependencias, se generan gr√°ficos en `resultados/`:
- M√©tricas, matriz de confusi√≥n, distribuci√≥n de clases
- Palabras importantes y radar comparativo

#### **Paso 9: Reporte JSON y persistencia**

Se exporta un reporte completo en `resultados/reporte_completo.json` y se guarda el modelo en `modelos/modelo_entrenado.pkl`.

### **Explicaci√≥n de Funciones Clave**

#### **Funci√≥n `_calcular_log_probabilidad()` en modelo.py**

Esta funci√≥n implementa el n√∫cleo del Teorema de Bayes:

```python
def _calcular_log_probabilidad(self, mensaje, clase):
    # Empezar con log(P(clase))
    log_prob = self.log_prob_spam if clase == 'spam' else self.log_prob_ham
    
    # Sumar log(P(palabra|clase)) para cada palabra
    for palabra in mensaje:
        if palabra in prob_palabras:
            log_prob += prob_palabras[palabra]
        else:
            # Manejo de palabras desconocidas (OOV)
            log_prob += log(prob_oov)
    
    return log_prob
```

**¬øPor qu√© logaritmos?**
- Multiplicar muchas probabilidades peque√±as puede causar underflow
- log(a √ó b) = log(a) + log(b), convertimos multiplicaci√≥n en suma
- M√°s estable num√©ricamente

#### **Funci√≥n `crear_bag_of_words()` en preprocesamiento.py**

Esta funci√≥n convierte texto en n√∫meros:

```python
def crear_bag_of_words(mensajes):
    # 1. Crear vocabulario: todas las palabras √∫nicas
    vocabulario = {palabra: indice for indice, palabra in enumerate(palabras_unicas)}
    
    # 2. Para cada mensaje, crear un vector
    for mensaje in mensajes:
        vector = [0] * len(vocabulario)
        for palabra in mensaje:
            indice = vocabulario[palabra]
            vector[indice] += 1  # Incrementar contador
```

**Ejemplo:**
- Vocabulario: {"dinero": 0, "f√°cil": 1, "reuni√≥n": 2}
- Mensaje: "dinero f√°cil dinero"
- Vector: [2, 1, 0] (dinero aparece 2 veces, f√°cil 1 vez, reuni√≥n 0 veces)

---

## **14. Instrucciones de Uso**

### **Requisitos del Sistema**

- **Python 3.7 o superior**
- **Sistema operativo**: Windows, macOS o Linux
- **Bibliotecas**: El pipeline base funciona con bibliotecas est√°ndar de Python. Para **visualizaciones** y an√°lisis avanzados se recomienda instalar `matplotlib`, `seaborn`, `numpy`.

### **Instalaci√≥n**

1. **Clonar o descargar el proyecto:**
   ```bash
   cd spam-detector-ai
   ```

2. **Verificar instalaci√≥n de Python:**
   ```bash
   python --version
   # Debe mostrar Python 3.7 o superior
   ```

3. **Instalar dependencias:**

   **Opci√≥n A: Usar script autom√°tico (recomendado en macOS/Linux):**
   ```bash
   ./instalar_dependencias.sh
   source venv/bin/activate
   ```

   **Opci√≥n B: Instalaci√≥n manual:**
   ```bash
   # Crear entorno virtual
   python3 -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   
   # Instalar dependencias
   pip install -r requirements.txt
   ```

   **Nota:** Si tienes problemas con el entorno gestionado de Python, el script autom√°tico crear√° un entorno virtual y instalar√° todo autom√°ticamente.

### **Ejecuci√≥n del Proyecto**

#### **Ejecutar el Pipeline Completo**

Simplemente ejecuta el script principal:

```bash
python main.py
```

Esto ejecutar√°:
1. Carga de datos
2. Preprocesamiento
3. Entrenamiento del modelo
4. Evaluaci√≥n
5. Ejemplos de predicci√≥n
6. An√°lisis de palabras importantes
7. An√°lisis estad√≠stico
8. Visualizaciones (si est√°n disponibles)
9. Reporte JSON y guardado del modelo

**Nota:** El script usa `datos_grande.csv` si existe; de lo contrario usa `datos.csv`.
Para generar el dataset grande ejecuta:
```bash
python generar_dataset_grande.py
```

#### **Salida Esperada**

El programa mostrar√°:
- Progreso de cada paso
- M√©tricas de evaluaci√≥n (accuracy, precision, recall, F1-score)
- Matriz de confusi√≥n
- Ejemplos de predicciones
- Palabras m√°s caracter√≠sticas de spam y ham
- An√°lisis estad√≠stico y recomendaciones
- Reporte JSON en `resultados/reporte_completo.json`
- Im√°genes en `resultados/` (si est√°n disponibles las dependencias)

### **Usar el Modelo para Clasificar Mensajes Propios**

Puedes cargar el modelo entrenado sin reentrenar:

```python
from preprocesamiento import preprocesar_mensaje
from modelo import NaiveBayesSpamDetector

# 1. Cargar el modelo guardado
modelo = NaiveBayesSpamDetector.cargar('modelos/modelo_entrenado.pkl')

# 2. Clasificar un nuevo mensaje
mensaje_nuevo = "Gana dinero r√°pido sin esfuerzo"
mensaje_preproc = preprocesar_mensaje(mensaje_nuevo)
prediccion = modelo.predecir(mensaje_preproc)
probabilidades = modelo.predecir_proba(mensaje_preproc)

print(f"Predicci√≥n: {prediccion}")
print(f"Probabilidades: Spam={probabilidades['spam']:.3f}, Ham={probabilidades['ham']:.3f}")
```

Primero ejecuta `python main.py` para generar el archivo `modelos/modelo_entrenado.pkl`.

Tambi√©n puedes usar el script interactivo:
```bash
python usar_modelo.py
```

### **Agregar Nuevos Datos**

Para agregar m√°s ejemplos al dataset:

1. Abre `datos.csv` o `datos_grande.csv`
2. Agrega nuevas filas con el formato:
   ```csv
   id,mensaje,etiqueta
   181,"Tu nuevo mensaje aqu√≠",spam
   ```
3. Aseg√∫rate de que las etiquetas sean exactamente 'spam' o 'ham'
4. Ejecuta `main.py` nuevamente para reentrenar

### **Modificar Par√°metros**

#### **Cambiar el porcentaje de datos de entrenamiento:**

En `main.py`, modifica:
```python
mensajes_train, mensajes_test, ... = dividir_datos(
    mensajes, etiquetas, 
    porcentaje_entrenamiento=0.7  # Cambiar de 0.8 a 0.7 (70% train, 30% test)
)
```

#### **Cambiar el par√°metro de suavizado:**

En `main.py`, modifica:
```python
modelo = NaiveBayesSpamDetector(alpha=0.5)  # Cambiar de 1.0 a 0.5
```

Valores m√°s altos de alpha dan m√°s peso a palabras desconocidas.

### **Troubleshooting**

**Error: "FileNotFoundError: datos.csv"**
- Aseg√∫rate de que `datos.csv` o `datos_grande.csv` est√©n en el mismo directorio que `main.py`
- Si falta el dataset grande, puedes generarlo con `python generar_dataset_grande.py`

**Error: "El modelo debe ser entrenado antes de hacer predicciones"**
- Ejecuta `modelo.entrenar()` antes de usar `modelo.predecir()`

**Advertencia: "Visualizaciones no disponibles"**
- Instala las dependencias con `pip install -r requirements.txt`

**Resultados muy bajos (accuracy < 0.7)**
- Revisa que el dataset est√© balanceado (similar cantidad de spam y ham)
- Verifica que los mensajes est√©n correctamente etiquetados
- Considera agregar m√°s datos de entrenamiento

---

## **15. An√°lisis de Resultados**

### **Interpretaci√≥n de las M√©tricas**

#### **Accuracy (Exactitud)**

**F√≥rmula:** (TP + TN) / Total

**Interpretaci√≥n:**
- **0.9 - 1.0**: Excelente - El modelo clasifica correctamente m√°s del 90% de los casos
- **0.8 - 0.9**: Bueno - Desempe√±o s√≥lido, pero hay margen de mejora
- **0.7 - 0.8**: Aceptable - Funciona, pero comete errores frecuentes
- **< 0.7**: Necesita mejoras - El modelo no est√° aprendiendo bien

**Limitaci√≥n:** Puede ser enga√±osa si hay desbalance de clases. Si hay 95% ham y 5% spam, predecir siempre "ham" dar√≠a 95% accuracy sin aprender nada √∫til.

#### **Precision (Precisi√≥n)**

**F√≥rmula:** TP / (TP + FP)

**Interpretaci√≥n:**
- **¬øQu√© significa?** Cuando el modelo dice "esto es spam", ¬øqu√© tan a menudo tiene raz√≥n?
- **Alta precisi√≥n (> 0.9)**: Pocos falsos positivos - No marcamos correos leg√≠timos como spam
- **Baja precisi√≥n (< 0.7)**: Muchos falsos positivos - Marcamos muchos correos leg√≠timos como spam (malo para el usuario)

**Importancia:** En spam detection, la precisi√≥n es cr√≠tica porque marcar correos leg√≠timos como spam es muy molesto para los usuarios.

#### **Recall (Sensibilidad)**

**F√≥rmula:** TP / (TP + FN)

**Interpretaci√≥n:**
- **¬øQu√© significa?** De todo el spam que existe, ¬øcu√°nto logramos capturar?
- **Alto recall (> 0.9)**: Capturamos casi todo el spam - Pocos falsos negativos
- **Bajo recall (< 0.7)**: Dejamos pasar mucho spam - Muchos falsos negativos (el spam llega a la bandeja de entrada)

**Importancia:** Tambi√©n es cr√≠tica porque dejar pasar spam es problem√°tico.

#### **F1-Score**

**F√≥rmula:** 2 √ó (Precision √ó Recall) / (Precision + Recall)

**Interpretaci√≥n:**
- Es un balance entre precisi√≥n y recall
- **Alto F1 (> 0.9)**: Buen balance entre capturar spam y no molestar a usuarios
- **Bajo F1 (< 0.7)**: Uno de los dos aspectos (precisi√≥n o recall) est√° fallando

**Ventaja:** Penaliza modelos que tienen una m√©trica muy alta y otra muy baja. Nos ayuda a encontrar el punto √≥ptimo.

### **Matriz de Confusi√≥n**

La matriz de confusi√≥n nos muestra exactamente d√≥nde est√° fallando el modelo:

```
                    Predicho
                  Spam    Ham
Realmente Spam     TP     FN
Realmente Ham      FP     TN
```

**Interpretaci√≥n:**
- **TP alto, FN bajo**: Bien - Capturamos la mayor√≠a del spam
- **TN alto, FP bajo**: Bien - No molestamos con falsas alarmas
- **FN alto**: Problema - Dejamos pasar mucho spam
- **FP alto**: Problema - Marcamos muchos correos leg√≠timos como spam

### **Qu√© Significan los Valores Obtenidos**

#### **Escenario Ideal (Buen Modelo):**
```
Accuracy:  0.92 (92% correcto)
Precision: 0.90 (90% de los "spam" predichos son realmente spam)
Recall:    0.93 (93% del spam real es capturado)
F1-Score:  0.91 (balance entre precisi√≥n y recall)
```

#### **Escenario con Baja Precisi√≥n:**
```
Precision: 0.60
```
**Problema:** Muchos correos leg√≠timos son marcados como spam  
**Soluci√≥n:** Ajustar el umbral de decisi√≥n o mejorar el entrenamiento

#### **Escenario con Bajo Recall:**
```
Recall: 0.55
```
**Problema:** Mucho spam no est√° siendo detectado  
**Soluci√≥n:** Agregar m√°s ejemplos de spam al entrenamiento, ajustar suavizado

### **An√°lisis de Palabras Importantes**

El modelo tambi√©n identifica las palabras m√°s caracter√≠sticas de cada clase:

**Palabras t√≠picas de SPAM:**
- dinero, gratis, r√°pido, gana, premio, click, millonario

**Palabras t√≠picas de HAM:**
- reuni√≥n, confirmaci√≥n, documento, informe, proyecto, gracias

Si estas palabras aparecen, el modelo est√° aprendiendo patrones correctos.

### **C√≥mo Mejorar el Modelo**

1. **Agregar m√°s datos:**
   - M√°s ejemplos mejoran la generalizaci√≥n
   - Idealmente, tener miles de ejemplos

2. **Balancear el dataset:**
   - Similar cantidad de spam y ham
   - Si hay desbalance, el modelo puede sesgarse

3. **Ajustar el preprocesamiento:**
   - Modificar la lista de stopwords
   - Considerar lematizaci√≥n (agrupar variaciones: "ganar", "gana", "ganando")

4. **Ajustar el par√°metro de suavizado:**
   - Probar diferentes valores de alpha (0.5, 1.0, 2.0)
   - Valores m√°s altos dan m√°s peso a palabras desconocidas

5. **Revisar y corregir etiquetas:**
   - Errores en las etiquetas del dataset afectan el aprendizaje
   - Validar manualmente algunos casos

6. **Considerar t√©cnicas avanzadas:**
   - N-gramas (pares de palabras en lugar de palabras individuales)
   - TF-IDF en lugar de conteo simple
   - Otros algoritmos (SVM, Random Forest) para comparar

---

## **16. Resultados Esperados**

Al ejecutar el proyecto, se generan los siguientes resultados:

### **M√©tricas de Desempe√±o**

Con el dataset peque√±o (`datos.csv`, 180 mensajes balanceados), se esperan resultados como:

| M√©trica | Valor Esperado | Interpretaci√≥n |
|---------|----------------|----------------|
| **Accuracy** | 0.85 - 0.95 | Excelente exactitud en la clasificaci√≥n |
| **Precision** | 0.80 - 0.95 | Baja tasa de falsos positivos |
| **Recall** | 0.80 - 0.95 | Alta capacidad de detectar spam |
| **F1-Score** | 0.82 - 0.93 | Balance adecuado entre m√©tricas |

### **Archivos Generados**

El script principal genera autom√°ticamente:

1. **Visualizaciones** (en `resultados/`):
   - `metricas_desempeno.png` - Gr√°fico de barras con todas las m√©tricas
   - `matriz_confusion.png` - Visualizaci√≥n de la matriz de confusi√≥n
   - `distribucion_clases.png` - Comparaci√≥n de distribuci√≥n de clases
   - `palabras_importantes.png` - Palabras clave por clase
   - `comparacion_metricas_radar.png` - Gr√°fico de radar comparativo
   - (Si no est√°n instaladas las dependencias, estas visualizaciones se omiten)

2. **Reportes**:
   - `reporte_completo.json` - Reporte detallado en formato JSON con todos los an√°lisis

### **An√°lisis Autom√°tico**

El sistema genera autom√°ticamente:
- An√°lisis estad√≠stico del dataset
- Identificaci√≥n de errores (falsos positivos y negativos)
- Interpretaci√≥n del desempe√±o
- Recomendaciones para mejorar el modelo

---

## **17. Estructura del Proyecto**

```
spam-detector-ai/
‚îú‚îÄ‚îÄ README.md                  # Documentaci√≥n completa del proyecto
‚îú‚îÄ‚îÄ LICENSE                    # Licencia MIT
‚îú‚îÄ‚îÄ INSTALACION.md             # Gu√≠a de instalaci√≥n
‚îú‚îÄ‚îÄ GUIA_MODELO_PERSISTENTE.md # Gu√≠a de persistencia del modelo
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
‚îú‚îÄ‚îÄ .gitignore                 # Archivos a ignorar en Git
‚îú‚îÄ‚îÄ datos.csv                  # Dataset peque√±o con 180 mensajes
‚îú‚îÄ‚îÄ datos_grande.csv           # Dataset grande con 1500 mensajes
‚îú‚îÄ‚îÄ generar_dataset_grande.py  # Generador del dataset grande
‚îÇ
‚îú‚îÄ‚îÄ preprocesamiento.py        # M√≥dulo de preprocesamiento de texto
‚îú‚îÄ‚îÄ modelo.py                  # Implementaci√≥n de Naive Bayes
‚îú‚îÄ‚îÄ evaluacion.py              # M√©tricas de evaluaci√≥n
‚îú‚îÄ‚îÄ visualizaciones.py         # Generaci√≥n de gr√°ficos profesionales
‚îú‚îÄ‚îÄ analisis.py                # An√°lisis estad√≠stico detallado
‚îú‚îÄ‚îÄ usar_modelo.py             # Uso del modelo guardado
‚îú‚îÄ‚îÄ main.py                    # Script principal del pipeline
‚îÇ
‚îú‚îÄ‚îÄ modelos/                   # Modelos guardados (se genera)
‚îî‚îÄ‚îÄ resultados/                # Directorio generado autom√°ticamente
    ‚îú‚îÄ‚îÄ metricas_desempeno.png
    ‚îú‚îÄ‚îÄ matriz_confusion.png
    ‚îú‚îÄ‚îÄ distribucion_clases.png
    ‚îú‚îÄ‚îÄ palabras_importantes.png
    ‚îú‚îÄ‚îÄ comparacion_metricas_radar.png
    ‚îî‚îÄ‚îÄ reporte_completo.json
```

---

## **18. Metodolog√≠a de Desarrollo**

### **Fases del Proyecto**

1. **An√°lisis del Problema**
   - Identificaci√≥n de la tarea de clasificaci√≥n binaria
   - Selecci√≥n del algoritmo apropiado (Naive Bayes)
   - Dise√±o de la arquitectura del sistema

2. **Preprocesamiento**
   - Normalizaci√≥n de texto
   - Tokenizaci√≥n y limpieza
   - Eliminaci√≥n de ruido (stopwords, puntuaci√≥n)

3. **Implementaci√≥n del Modelo**
   - Desarrollo desde cero del algoritmo Naive Bayes
   - Implementaci√≥n del suavizado de Laplace
   - Optimizaci√≥n para estabilidad num√©rica

4. **Evaluaci√≥n**
   - Divisi√≥n train/test
   - C√°lculo de m√©tricas est√°ndar
   - An√°lisis de errores

5. **Visualizaci√≥n y An√°lisis**
   - Generaci√≥n de gr√°ficos profesionales
   - An√°lisis estad√≠stico detallado
   - Exportaci√≥n de reportes

### **Decisiones de Dise√±o**

- **Naive Bayes**: Elegido por su simplicidad, eficiencia y buen desempe√±o en NLP
- **Suavizado de Laplace**: Para manejar palabras no vistas en entrenamiento
- **Log-probabilidades**: Para evitar problemas de underflow num√©rico
- **M√≥dulos separados**: Para facilitar mantenimiento y comprensi√≥n

---

## **19. Trabajos Futuros y Mejoras**

### **Mejoras Propuestas**

1. **Expansi√≥n del Dataset**
   - Aumentar a miles de ejemplos
   - Incluir m√°s variabilidad en los mensajes
   - Datos de m√∫ltiples fuentes

2. **T√©cnicas Avanzadas**
   - Implementar n-gramas (bigramas, trigramas)
   - Usar TF-IDF en lugar de conteo simple
   - Considerar lematizaci√≥n y stemming

3. **Modelos Alternativos**
   - Comparar con SVM, Random Forest, Redes Neuronales
   - Ensambles de modelos
   - Modelos preentrenados (BERT, etc.)

4. **Optimizaci√≥n**
   - Optimizaci√≥n de hiperpar√°metros
   - Validaci√≥n cruzada (k-fold)
   - An√°lisis de caracter√≠sticas m√°s detallado

5. **Interfaz de Usuario**
   - Crear API REST
   - Desarrollar interfaz web
   - Aplicaci√≥n m√≥vil

---

## **20. Referencias y Bibliograf√≠a**

### **Referencias Acad√©micas**

1. **Mitchell, T. M.** (1997). *Machine Learning*. McGraw-Hill.
   - Fundamentos de aprendizaje autom√°tico y clasificaci√≥n

2. **Manning, C. D., Raghavan, P., & Sch√ºtze, H.** (2008). *Introduction to Information Retrieval*. Cambridge University Press.
   - Procesamiento de texto y clasificaci√≥n de documentos

3. **Russell, S., & Norvig, P.** (2020). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.
   - Algoritmos de IA y razonamiento probabil√≠stico

### **Recursos T√©cnicos**

- **Scikit-learn Documentation**: https://scikit-learn.org/
  - Referencia para implementaciones de machine learning

- **NLTK Book**: https://www.nltk.org/book/
  - Procesamiento de lenguaje natural

- **Towards Data Science**: https://towardsdatascience.com/
  - Art√≠culos sobre Naive Bayes y clasificaci√≥n de texto

### **Documentaci√≥n de Python**

- **Python Documentation**: https://docs.python.org/3/
- **Matplotlib Documentation**: https://matplotlib.org/
- **NumPy Documentation**: https://numpy.org/doc/

---

## **21. Agradecimientos**

Este proyecto fue desarrollado como trabajo final del curso de Inteligencia Artificial, implementando desde cero un sistema completo de clasificaci√≥n de texto utilizando t√©cnicas fundamentales de machine learning.

---

## **22. Informaci√≥n de Contacto y Licencia**

- **Licencia**: MIT License (ver archivo LICENSE)
- **Autor**: [Tu Nombre]
- **Instituci√≥n**: [Nombre de la Universidad]
- **Curso**: Inteligencia Artificial
- **A√±o**: 2026

---

**Nota Final**: Este proyecto demuestra la implementaci√≥n completa de un sistema de clasificaci√≥n de texto desde cero, incluyendo preprocesamiento, modelado, evaluaci√≥n y an√°lisis. El c√≥digo est√° dise√±ado para ser educativo, bien documentado y f√°cil de entender, ideal para prop√≥sitos acad√©micos y de aprendizaje.

---
