# üìå **Proyecto de IA ‚Äî Algoritmo de Aprendizaje Supervisado**  
## ‚≠ê *Clasificaci√≥n de Correos: ¬øSpam o No Spam?*

---

## **1. Descripci√≥n del Problema**

Este proyecto aborda la tarea de **clasificar autom√°ticamente correos electr√≥nicos** para determinar si un mensaje es *spam* (correo no deseado) o *ham* (correo leg√≠timo).  
El objetivo es entrenar un modelo desde cero que aprenda a identificar patrones en el texto para realizar predicciones correctas.

Este problema es adecuado para un proyecto de IA porque:

- Es f√°cil de comprender y replicar.  
- Puede resolverse sin modelos preentrenados.  
- Permite aplicar t√©cnicas b√°sicas de procesamiento de texto y aprendizaje autom√°tico.  
- Dispone de datos simples y etiquetados.

---

## **2. Tipo de Aprendizaje Utilizado: Aprendizaje Supervisado**

El aprendizaje supervisado consiste en entrenar un modelo a partir de:

- **Datos de entrada**: los mensajes de correo.  
- **Etiquetas conocidas**: spam / ham.

El objetivo del modelo es aprender una funci√≥n:

\[
f(x) \rightarrow y
\]

donde:  
- \(x\) representa las caracter√≠sticas extra√≠das del mensaje,  
- \(y\) es la etiqueta asignada al mensaje.

La tarea es una **clasificaci√≥n binaria**, lo que la hace ideal para introducir los fundamentos del aprendizaje supervisado.

---

## **3. Conjunto de Datos**

Para este estudio se emplea un dataset peque√±o, como el siguiente ejemplo:

| id | mensaje                                        | etiqueta |
|----|------------------------------------------------|----------|
| 1  | "Gana dinero r√°pido haciendo clic aqu√≠"        | spam     |
| 2  | "Reuni√≥n confirmada para ma√±ana"               | ham      |
| 3  | "Oferta limitada, compra ahora"                | spam     |
| 4  | "Adjunto env√≠o los documentos solicitados"     | ham      |

El conjunto puede ampliarse para obtener mejores resultados, pero este tama√±o permite mostrar el funcionamiento del modelo de forma clara.

---

## **4. Preprocesamiento de Datos**

El texto se procesa mediante los siguientes pasos:

1. Conversi√≥n a min√∫sculas.  
2. Eliminaci√≥n de signos de puntuaci√≥n.  
3. Tokenizaci√≥n.  
4. Eliminaci√≥n de palabras irrelevantes (stopwords).  
5. Conversi√≥n del texto a representaci√≥n num√©rica mediante **Bolsa de Palabras (Bag of Words)**.

El resultado es que cada mensaje se vuelve un vector que indica la frecuencia de palabras relevantes.

---

## **5. Modelo Seleccionado: Naive Bayes**

### **¬øPor qu√© Naive Bayes?**

- Es simple de implementar desde cero.  
- Funciona especialmente bien con texto.  
- Tiene bajo costo computacional.  
- Se basa en fundamentos estad√≠sticos claros.

### **Idea del Modelo**

El modelo calcula:

\[
P(\text{spam} \mid \text{mensaje})
\quad \text{y} \quad
P(\text{ham} \mid \text{mensaje})
\]

Asignando al mensaje la clase con mayor probabilidad.

Para evitar que palabras nuevas produzcan errores, se utiliza **suavizado de Laplace**:

\[
P(\text{palabra}|\text{clase}) = \frac{\text{frecuencia} + 1}{\text{total palabras} + V}
\]

donde \(V\) es el tama√±o del vocabulario.

---

## **6. Entrenamiento del Modelo**

Durante el entrenamiento se calculan:

- La probabilidad de que un mensaje sea spam o ham.  
- La frecuencia de cada palabra en ambos tipos de mensajes.  
- Las probabilidades condicionales de cada palabra seg√∫n la clase.  

As√≠ el modelo aprende qu√© t√©rminos son m√°s comunes en correos no deseados y cu√°les aparecen en mensajes leg√≠timos.

---

## **7. Evaluaci√≥n del Modelo**

Se utilizan las m√©tricas cl√°sicas:

- **Accuracy (Exactitud)**  
- **Precision (Precisi√≥n)**  
- **Recall (Sensibilidad)**  
- **F1-score**

Un ejemplo esperado con un dataset peque√±o:

| M√©trica   | Valor |
|-----------|-------|
| Accuracy  | 0.92  |
| Precisi√≥n | 0.90  |
| Recall    | 0.93  |
| F1-score  | 0.91  |

---

## **8. Resultados y An√°lisis**

El modelo logra distinguir t√©rminos clave que indican spam, como:

- ‚Äúdinero‚Äù,  
- ‚Äúr√°pido‚Äù,  
- ‚Äúclic‚Äù,  
- ‚Äúcompra‚Äù,  
- ‚Äúoferta‚Äù.

Mientras que los correos ham presentan vocabulario m√°s formal y administrativo.

El desempe√±o del algoritmo muestra que **Naive Bayes es adecuado para tareas de clasificaci√≥n de texto simples**.

---

## **9. Limitaciones**

- No capta el orden de las palabras.  
- Supone independencia entre t√©rminos, lo cual no siempre es cierto.  
- Puede fallar en textos ir√≥nicos o muy ambiguos.  
- Requiere un buen preprocesamiento para lograr buenos resultados.

---

## **10. Conclusiones**

- El problema de clasificaci√≥n de correos es ideal para aprendizaje supervisado.  
- Naive Bayes permite implementar un modelo desde cero, sencillo y eficiente.  
- A pesar de su simplicidad, ofrece buena precisi√≥n en tareas de filtrado de spam.  
- Con mayor cantidad de datos, el modelo podr√≠a mejorar a√∫n m√°s su rendimiento.

---
